{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform the PDB structure of protein to the distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data_example/K_site/me_name_seq_K_have_PDB_alphafold.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/Users/gly/gly_github_code/graphmethysite/src/data_proprecess/calculate_Adj.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgly/home/Users/gly/gly_github_code/graphmethysite/src/data_proprecess/calculate_Adj.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgly/home/Users/gly/gly_github_code/graphmethysite/src/data_proprecess/calculate_Adj.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m site_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mK\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgly/home/Users/gly/gly_github_code/graphmethysite/src/data_proprecess/calculate_Adj.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m name_seq \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../data_example/\u001b[39;49m\u001b[39m{\u001b[39;49;00msite_type\u001b[39m}\u001b[39;49;00m\u001b[39m_site/me_name_seq_\u001b[39;49m\u001b[39m{\u001b[39;49;00msite_type\u001b[39m}\u001b[39;49;00m\u001b[39m_have_PDB_alphafold.npy\u001b[39;49m\u001b[39m'\u001b[39;49m,allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgly/home/Users/gly/gly_github_code/graphmethysite/src/data_proprecess/calculate_Adj.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgly/home/Users/gly/gly_github_code/graphmethysite/src/data_proprecess/calculate_Adj.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# save_path='/home/chentb/RAID_data/chentb_data/methylation_data/distance_matrix/'\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GCN/lib/python3.8/site-packages/numpy/lib/npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    388\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    391\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data_example/K_site/me_name_seq_K_have_PDB_alphafold.npy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "from Bio.PDB.NeighborSearch import NeighborSearch\n",
    "import Bio.PDB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "site_type=\"K\"\n",
    "name_seq = np.load(f'../data_example/{site_type}_site/me_name_seq_{site_type}_have_PDB_alphafold.npy',allow_pickle=True).item()\n",
    "count=0\n",
    "\n",
    "# save_path='/home/chentb/RAID_data/chentb_data/methylation_data/distance_matrix/'\n",
    "save_path=f'../graph_information/PDB_Structure/distance_matrix/{site_type}_site/'\n",
    "os.makedirs(save_path,exist_ok=True)\n",
    "for name in tqdm(name_seq):\n",
    "    try :\n",
    "        p = PDBParser()\n",
    "        structure= p.get_structure(name,'/home/Users/gly/Alphafold_database/UP000005640_9606_HUMAN/AF-'+name+'-F1-model_v1.pdb')\n",
    "        # structure= p.get_structure(name,f'{save_path}AF-'+name+'-F1-model_v1.pdb')\n",
    "    except FileNotFoundError: \n",
    "        continue\n",
    "    else:\n",
    "        for model in structure:\n",
    "            for chain in model:\n",
    "                distance_matrix=np.zeros((len(chain),len(chain)))            \n",
    "                for i in range(1,len(chain)+1):\n",
    "                    for j in range(i+1,len(chain)+1):\n",
    "                        distance_matrix[i-1][j-1]=chain[i][\"CA\"]-chain[j][\"CA\"]\n",
    "                        distance_matrix[j-1][i-1]=chain[i][\"CA\"]-chain[j][\"CA\"]\n",
    "                    np.save(f'{save_path}{name}.npy',distance_matrix)\n",
    "    # break \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjacency matrix (Example of lysine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adj_matrix(distance,site_kind):\n",
    "    # site_kind=\"K\"\n",
    "    count=0\n",
    "    path=f\"../../dat/data_example/{site_kind}_site/\"\n",
    "    print('Let\\'s start working on the distance matrix...')\n",
    "    name_seq = np.load(path+f'me_name_seq_{site_kind}_have_PDB_alphafold.npy',allow_pickle=True).item()\n",
    "    # save_ori_path=f'../graph_information/PDB_Structure/distance_matrix/{site_kind}_site'\n",
    "    save_path=f'../../dat/graph_information/{site_kind}_site/Adj_matrix_{str(float(distance))}'\n",
    "    try:\n",
    "        os.makedirs(save_path,exist_ok=True)\n",
    "    except FileExistsError:\n",
    "        print('File exists')\n",
    "    \n",
    "    for name in tqdm(list(name_seq.keys())):\n",
    "        if name+'.npy' not in os.listdir(save_path):\n",
    "            try:\n",
    "                posit_matrix=np.load(f\"../../dat/graph_information/PDB_Structure/distance_matrix/{site_kind}_site/{name}.npy\") #your PDB save npy\n",
    "            except FileNotFoundError: \n",
    "                # print(name)\n",
    "                count=count+1\n",
    "                length=posit_matrix.shape[0]\n",
    "                adj_matrix_bo=np.zeros([length,length])\n",
    "                for i in range(length):\n",
    "                    for j in range(i+1,length):\n",
    "                        if posit_matrix[i][j]<=distance:\n",
    "                            adj_matrix_bo[i][j]=1\n",
    "                            adj_matrix_bo[j][i]=1\n",
    "                np.save(save_path+'/'+name+'.npy',adj_matrix_bo)\n",
    "    # print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(adj, site, hop):\n",
    "    output = []\n",
    "    Q = []\n",
    "    Q.append(site)\n",
    "    for i in range(hop+1):\n",
    "        temp=[]\n",
    "        while Q != []:\n",
    "            v = Q.pop(0)\n",
    "            output.append(v)\n",
    "            for n ,t in enumerate(adj[v]):\n",
    "                if t==1 and n not in Q and n not in temp and n not in output:\n",
    "                    temp.append(n)\n",
    "        # print(temp)\n",
    "        Q=Q+temp\n",
    "        # print(Q)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extracted (One hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(sentence):\n",
    "    word_index={'M': 0,\n",
    "    'I': 1,\n",
    "    'P': 2,\n",
    "    'L': 3,\n",
    "    'A': 4,\n",
    "    'C': 5,\n",
    "    'V': 6,\n",
    "    'G': 7,\n",
    "    'T': 8,\n",
    "    'Y': 9,\n",
    "    'D': 10,\n",
    "    'S': 11,\n",
    "    'Q': 12,\n",
    "    'W': 13,\n",
    "    'F': 14,\n",
    "    'K': 15,\n",
    "    'R': 16,\n",
    "    'E': 17,\n",
    "    'N': 18,\n",
    "    'H': 19,\n",
    "    'U': 20,\n",
    "    'X': 21}\n",
    "    sequence = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            sequence.append(word_index[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return sequence\n",
    "def onehot_feature(seq):\n",
    "    X_data=np.array(list(map(get_index, [seq])))\n",
    "    embedding_matrix_onehot=np.eye(22)\n",
    "    return embedding_matrix_onehot[X_data[0],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def positive_data(distance,hop,site_kind): \n",
    "    # hop=float(hop)\n",
    "    count=0 #calculate the number proteins that could not generate graphs\n",
    "    model_path=f\"../../dat/data_example/{site_kind}_site/feature_model/\"\n",
    "    w2v_model = Word2Vec.load(f\"{model_path}withX_word2vec_{site_kind}.model\")\n",
    "    embedding_matrix_word2vec = w2v_model.wv.vectors\n",
    "    vocab_list = list(w2v_model.wv.vocab.keys())\n",
    "    word_index = {word: index for index, word in enumerate(vocab_list)}\n",
    "    path=\"../../dat/data_example/\"+site_kind+\"_site\"\n",
    "    name_seq=np.load(f'{path}/me_name_seq_{site_kind}_have_PDB_alphafold.npy',allow_pickle=True).item()\n",
    "    print('Start processing positive data')\n",
    "    positive_no=np.load(path+'/me_positive_name_site_'+site_kind+'_have_PDB_alphafold.npy',allow_pickle=True).item()\n",
    "    save_path='../../dat/embedding_data/'+str(hop)+'_hop_'+str(float(distance))+'_'+site_kind+'/positive'\n",
    "    try:\n",
    "        os.makedirs(save_path+'/adj')\n",
    "        os.makedirs(save_path+'/feat_onehot')\n",
    "        os.makedirs(save_path+'/feat_word2vec')\n",
    "        os.makedirs(save_path+'/seq')\n",
    "    except FileExistsError:  \n",
    "        print('FileExists')\n",
    "\n",
    "    # positive_site=[]\n",
    "    # temp=np.load(f'/home/Users/gly/gly_me/data_process/{site_kind}_site/me_positive_name_site_{site_kind}_have_PDB_alphafold.npy',allow_pickle=True).item()\n",
    "    # for i,j in temp.items():\n",
    "    #     for k in range(len(j)):\n",
    "    #         positive_site.append(str(j[k]))\n",
    "    # # print(positive_site)\n",
    "    # print(name_seq)\n",
    "    for name in tqdm(name_seq):\n",
    "        try:\n",
    "            adj_matrix=np.load(f'../../dat/graph_information/PDB_Structure/distance_matrix/{site_kind}_site/{name}.npy')\n",
    "        except FileNotFoundError: \n",
    "            # feature_matrix=np.load('/home/chentb/alphafold_database/feature_matrix_1/'+name+'.npy')\n",
    "            sites=positive_no[name]\n",
    "            for site in sites:\n",
    "                try:\n",
    "                    num=bfs(adj_matrix,site-1,hop)\n",
    "                except IndexError:\n",
    "                    print(name,site)\n",
    "                seq=[]\n",
    "                word2vec_seq='X'+name_seq[name]+'X'\n",
    "                freture_ix_leaft=[]\n",
    "                freture_ix_right=[]\n",
    "                for i in num:\n",
    "                    # print(\"seq:\",seq)\n",
    "                    # print(\"name:\",name_seq[name][i])\n",
    "                    try:\n",
    "                        name_seq[name][i]\n",
    "                    except IndexError:\n",
    "                        print(name,i)\n",
    "                    seq.append(name_seq[name][i])\n",
    "                    ix_seq_leaft=word2vec_seq[i:i+2]\n",
    "                    ix_seq_right=word2vec_seq[i+1:i+3]\n",
    "                    freture_ix_leaft.append(word_index[ix_seq_leaft])\n",
    "                    freture_ix_right.append(word_index[ix_seq_right])\n",
    "                temp_feature_right=embedding_matrix_word2vec[freture_ix_right]\n",
    "                temp_feature_leaft=embedding_matrix_word2vec[freture_ix_leaft]\n",
    "                word2vec_feature=temp_feature_right+temp_feature_leaft\n",
    "\n",
    "                temp_adj_matrix=adj_matrix[num][:,num]\n",
    "\n",
    "                np.save(save_path+'/seq/'+name+'_'+str(site)+'.npy', num)\n",
    "                np.save(save_path+'/adj/'+name+'_'+str(site)+'.npy',temp_adj_matrix)\n",
    "                np.save(save_path+'/feat_onehot/'+name+'_'+str(site)+'.npy',onehot_feature(seq))\n",
    "                np.save(save_path+'/feat_word2vec/'+name+'_'+str(site)+'.npy',word2vec_feature)\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_data(distance,hop,site_kind):\n",
    "    # hop=float(hop)\n",
    "    model_path=f\"../data_example/{site_kind}_site/feature_model/\"\n",
    "    w2v_model = Word2Vec.load(f\"{model_path}withX_word2vec_{site_kind}.model\")\n",
    "    embedding_matrix_word2vec = w2v_model.wv.vectors\n",
    "    vocab_list = list(w2v_model.wv.vocab.keys())\n",
    "    word_index = {word: index for index, word in enumerate(vocab_list)}\n",
    "    count=0\n",
    "    path=f\"../data_example/{site_kind}_site/\"\n",
    "    name_seq=np.load(path+f'me_name_seq_{site_kind}_have_PDB_alphafold.npy',allow_pickle=True).item()\n",
    "    print('Start processing negative data')\n",
    "    negative_name_no=np.load(path+f'/me_negative_name_site_{site_kind}_have_PDB_alphafold.npy',allow_pickle=True).item()\n",
    "    save_path='../embedding_data/'+str(hop)+'_hop_'+str(float(distance))+'_'+site_kind+'/negative'\n",
    "    try:\n",
    "        os.makedirs(save_path+'/adj')\n",
    "        os.makedirs(save_path+'/feat_onehot')\n",
    "        os.makedirs(save_path+'/feat_word2vec')\n",
    "        os.makedirs(save_path+'/seq')\n",
    "    except FileExistsError:\n",
    "        print('FileExistsError')\n",
    "    for name in tqdm(name_seq):\n",
    "        try:\n",
    "            adj_matrix=np.load(f'../graph_information/PDB_Structure/distance_matrix/{site_kind}_site/{name}.npy')\n",
    "        except FileNotFoundError: \n",
    "            count+=1\n",
    "            continue\n",
    "        else:\n",
    "            sites=negative_name_no[name]\n",
    "            for site in sites:\n",
    "                try:\n",
    "                    num=bfs(adj_matrix,site-1,hop)\n",
    "                except IndexError:\n",
    "                    print(name,site)\n",
    "                seq=[]\n",
    "                word2vec_seq='X'+name_seq[name]+'X'\n",
    "                freture_ix_leaft=[]\n",
    "                freture_ix_right=[]\n",
    "                for i in num:\n",
    "                    seq.append(name_seq[name][i])\n",
    "                    ix_seq_leaft=word2vec_seq[i:i+2]\n",
    "                    ix_seq_right=word2vec_seq[i+1:i+3]\n",
    "                    freture_ix_leaft.append(word_index[ix_seq_leaft])\n",
    "                    freture_ix_right.append(word_index[ix_seq_right])\n",
    "                temp_feature_right=embedding_matrix_word2vec[freture_ix_right]\n",
    "                temp_feature_leaft=embedding_matrix_word2vec[freture_ix_leaft]\n",
    "                word2vec_feature=temp_feature_right+temp_feature_leaft\n",
    "\n",
    "                temp_adj_matrix=adj_matrix[num][:,num]\n",
    "\n",
    "                np.save(save_path+'/seq/'+name+'_'+str(site)+'.npy', num)\n",
    "                np.save(save_path+'/adj/'+name+'_'+str(site)+'.npy',temp_adj_matrix)\n",
    "                np.save(save_path+'/feat_onehot/'+name+'_'+str(site)+'.npy',onehot_feature(seq))\n",
    "                np.save(save_path+'/feat_word2vec/'+name+'_'+str(site)+'.npy',word2vec_feature)\n",
    "    print(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start working on the distance matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 742/742 [00:00<00:00, 3387.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing positive data\n",
      "FileExists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 742/742 [00:01<00:00, 478.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "site_kind='R'\n",
    "Adj_matrix(14.0523,site_kind=site_kind) #defaul distance threshold is 10\n",
    "positive_data(14.0523,4,site_kind)\n",
    "# negative_data(10,3,site_kind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 117/742 [00:00<00:01, 453.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P62273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 264/742 [00:00<00:01, 428.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P50238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 490/742 [00:01<00:00, 545.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q92686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 742/742 [00:01<00:00, 511.17it/s]\n"
     ]
    }
   ],
   "source": [
    "site_type=\"R\"\n",
    "name_seq = np.load(f'../../dat/data_example/{site_type}_site/me_name_seq_{site_type}_have_PDB_alphafold.npy',allow_pickle=True).item()\n",
    "for name in tqdm(name_seq):\n",
    "# protein=\"A0AVF1_12\"\n",
    "    path=f\"/home/Users/gly/gly_github_code/graphmethysite/dat/graph_information/R_site/Adj_matrix_14.0523/{name}.npy\"\n",
    "    file=np.load(f\"{path}\",allow_pickle=True)\n",
    "    if len(file)<80:\n",
    "        print(f\"{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "path=f\"/home/Users/gly/gly_github_code/graphmethysite/dat/graph_information/PDB_Structure/distance_matrix/R_site/P62273.npy\"\n",
    "file=np.load(f\"{path}\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a11d0628d139d7e7c9149788f5917d633070c657f6dcf48713f9630f1a0a32ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('GCN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a11d0628d139d7e7c9149788f5917d633070c657f6dcf48713f9630f1a0a32ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
